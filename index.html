<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="OSSPREY: Open Source Software PRojEct sustainabilitY tracker">
  <meta name="keywords" content="OSS">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EvidenceBot</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="figs/EvidenceBotLogo.webp">

  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script data-goatcounter="https://ossprey-web-analytics.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>

<style>
  ol li {
  margin-bottom: 1em; 
}

  a {
    text-decoration: none;
  }

  body {
    font-size: 18px;
  }
</style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://decallab.cs.ucdavis.edu/" target="_blank">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          Previously Built Tools
        </a>
        <div class="navbar-dropdown">
      
          <a class="navbar-item" href="https://oss-prey.github.io/OSSPREY-Website/" target="_blank">
            OSSPREY
          </a>
          
          <a class="navbar-item" href="https://ossreacts.netlify.app/" target="_blank">
            ReACTive
          </a>
          <!-- <a class="navbar-item" href="https://github.com/Nafiz43/EvidenceBot" target="_blank">
            EvidenceBot
          </a> -->
        </div>
      </div>


      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          Related Research
        </a>
        <div class="navbar-dropdown">  
          <a class="navbar-item" href="https://dl.acm.org/doi/abs/10.1145/3468264.3468563" target="_blank">
            Sustainability Forecasting
          </a>

          <a class="navbar-item" href="https://dl.acm.org/doi/abs/10.1145/3524842.3528506" target="_blank">
            APEX
          </a>
        
          <a class="navbar-item" href="https://dl.acm.org/doi/abs/10.1145/3663529.3663777" target="_blank">
            Researched ACTionable (ReACT)
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <img src="figs/EvidenceBotLogo.webp" alt="OSSPREY System Architecture" style="height: 120px; width: 125px;">
          <h1 class="title is-1 publication-title">EvidenceBot: A Privacy-Preserving, Customizable RAG-Based Tool for Enhancing Large Language Model Interactions</h1>
          <div class="is-size-5 publication-authors">

            <span class="author-block">
              <a href="https://nafiz43.github.io/portfolio/" target="_blank">Nafiz Imtiaz Khan</a>,
            </span>

            <span class="author-block">
              <a href="https://www.cs.ucdavis.edu/~filkov/" target="_blank">Vladimir Filkov</a>
            </span>
           
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Department of Computer Science, University of California, Davis</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1lSl8PXrCvKIuOCeOzNE0KIPx-CMAP6OS/view"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Live Link. -->
              <!-- <span class="link-block">
                <a href="https://ossprey.netlify.app" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-rocket"></i>
                  </span>
                  <span>Live</span>
                </a>
              </span> -->


              <!-- User Guide -->
            <span class="link-block">
              <a href="#user-guide" target="_blank"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-book"></i>
                </span>
                <span>User Guide</span>
                </a>
          </span>


              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Nafiz43/EvidenceBot" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://zenodo.org/records/15307373" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </span> -->


          


              <!-- Installation Manual. -->
            <span class="link-block">
              <a href="#Installation" target="_blank"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-tools"></i>
                </span>
                <span>Install</span>
                </a>
          </span>

          <span class="link-block">
            <a href="#Docker" target="_blank"
               class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-docker"></i>
              </span>
              <span>Docker</span>
              </a>
        </span>



          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Large Language Models (LLMs) have become pivotal in reshaping the world by enabling advanced natural language processing tasks such as document analysis, content generation, and conversational assistance. Their ability to process and generate human-like text has unlocked unprecedented opportunities across different domains such as healthcare, education, finance, and more. However, commercial LLM platforms face several limitations, including data privacy concerns, context size restrictions, lack of parameter configurability, and limited evaluation capabilities. These shortcomings hinder their effectiveness, particularly in scenarios involving sensitive information, large-scale document analysis, or the need for customized output. This underscores the need for a tool that combines the power of LLMs with enhanced privacy, flexibility, and usability.
          </p>

          <p>
          To address these challenges, we present <strong>EvidenceBot</strong>, a local, Retrieval-Augmented Generation (RAG)-based solution designed to overcome the limitations of commercial LLM platforms. EvidenceBot enables secure and efficient processing of large document sets through its privacy-preserving RAG pipeline, which extracts and appends only the most relevant text chunks as context for queries. The tool allows users to experiment with hyperparameter configurations, optimizing model responses for specific tasks, and includes an evaluation module to assess LLM performance against ground truths using semantic and similarity-based metrics. By offering enhanced privacy, customization, and evaluation capabilities, EvidenceBot bridges critical gaps in the LLM ecosystem, providing a versatile resource for individuals and organizations seeking to leverage LLMs effectively.
          </p>

           <!-- <p>To learn more about OSSPREY, visit our live link at <a href="https://ossprey.netlify.app" target="_blank">ossprey.netlify.app</a>.</p> -->
           <!-- <p style="color: red; font-weight: bold;">
            Note: Due to compute constraints, the tool has been limited to a subset of Github projects for the time being. Apologies in advance until we expand the tool's domain soon!
          </p> -->
        </div>
      </div>
    </div>
  </div>
</section>



<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">System Architecture</h2>
        <div class="content has-text-justified">

        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="section" id="System-Architecture">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">System Architecture</h2>
        <div class="content has-text-justified">

          <!-- System Architecture Image -->
          <figure class="image is-4by3">
            <img src="figs/EvidenceBotArchitecture.png" alt="EvidenceBot System Architecture" style="height: 70%; width: 100%;">
            <figcaption class="has-text-centered is-size-6 mt-2">Figure: System architecture of EvidenceBot</figcaption>
          </figure>


           <p>
            The architecture of the proposed pipeline is shown in the system diagram. The pipeline is capable of processing documents in various formats, such as <code>HTML</code>, <code>txt</code>, <code>md</code>, <code>py</code>, <code>pdf</code>, <code>csv</code>, <code>xlsx</code>, and <code>docx</code>. To handle these different file types, the pipeline utilizes the <code>LangChain</code> document loader.
          </p>

          <p>
            Once the documents are loaded, they are divided into smaller text chunks (default size = 512 tokens), with the option for the user to adjust the chunk size, thus controlling the number of chunks created for the given set of documents. These text chunks are then converted into embeddings using a preselected embedding model.
          </p>

          <p>
            Following this, the pipeline leverages <code>LangChain</code> to generate semantic indexes for each embedding, facilitating the retrieval and ranking of relevant information based on context and meaning, rather than relying on simple keyword matching. These embeddings and their corresponding semantic indexes are stored in <code>ChromaDB</code>, a high-performance vector database optimized for efficient similarity search.
          </p>

          <p>
            When a user submits a query, the pipeline converts it into an embedding using the same model as previously used for the documents. Then a semantic search is performed within the vector database, returning the top <em>k</em> most relevant results. The user can specify the value of <em>k</em> within the tool. These relevant text snippets are appended to the user's query and passed to the language model to ensure that the model has the complete context required to generate an accurate response. For compiling and running the language models, we used <code>Ollama</code>, which is an open-source platform that facilitates the deployment and management of local LLM models.
          </p>

          <p>
            The EvidenceBot dashboard uses <code>Streamlit</code>, <code>HTML</code>, and <code>CSS</code> to create an intuitive, interactive user interface. <code>Streamlit</code> works as the primary framework, which enables integration with <code>Python</code> logic and language models while managing user inputs, file uploads, and dynamic outputs. <code>HTML</code> structures key elements such as the navigation bar, input forms, and chat containers, and <code>CSS</code> is used to enhance the visual design, setting background colors, adjusting container layouts, and ensuring responsiveness. The combination of these tools ensures a streamlined user experience.
          </p>


        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="user-guide">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">
          <i class="fas fa-tools"></i> User Guide
        </h2>
        <div class="content has-text-justified">

          <h3 class="title is-4">Generating Individual Responses</h3>
          <p>The application is, by default, accessible at the following 
            <a href="http://localhost:8501" target="_blank">link</a> on the local machine. In this mode, users can provide a prompt and receive responses generated by a selected Large Language Model (LLM). Users can also adjust several model parameters as described in the <strong>Application Parameters</strong> section.
          </p>
          <p>The model selector dynamically lists all LLMs installed locally. Upon query submission, the system builds a vector database from files placed in the <code>DATA_DOCUMENTS</code> folder. Relevant chunks are retrieved and provided as context to the model for response enhancement.</p>
          <p>If any parameters are changed, the application should be restarted to regenerate the vector database accordingly.</p>
          <figure>
            <img src="figs/gen_ind_pre.jpeg" alt="Generate Individual Responses Functionality">
            <figcaption>Figure 1: Generate Individual Responses Functionality</figcaption>
          </figure>
          <p>Responses are logged in the <code>logs/history.csv</code> file along with timestamps, original prompts, and source content.</p>
          <figure>
            <img src="figs/gen_ind_post.jpeg" alt="Generate Individual Responses Output">
            <figcaption>Figure 2: Generate Individual Responses Output</figcaption>
          </figure>

          <h3 class="title is-4">Generating Batch Responses</h3>
          <p>Selecting the <em>Batch Question Mode</em> enables processing a list of questions via uploaded <code>.csv</code> file. Each row should contain a single question, processed sequentially by the model.</p>
          <figure>
            <img src="figs/gen_batch_pre.jpeg" alt="Generate Batch Responses Functionality">
            <figcaption>Figure 3: Generate Batch Responses Functionality</figcaption>
          </figure>
          <p>Progress is tracked during execution, and results are saved in <code>logs/history.csv</code>.</p>
          <figure>
            <img src="figs/gen_batch_post.jpeg" alt="Generate Batch Responses Output">
            <figcaption>Figure 4: Generate Batch Responses Output</figcaption>
          </figure>
          <figure>
            <img src="figs/gen_batch_post2.jpeg" alt="Generate Batch Responses Output File Format">
            <figcaption>Figure 5: Generate Batch Responses Output File Format</figcaption>
          </figure>

          <h3 class="title is-4">Evaluating Individual Responses</h3>
          <p>To evaluate an individual response, use the <code>Evaluate</code> mode at 
            <a href="http://localhost:8502" target="_blank">localhost:8502</a>. Users must input both the reference and generated texts for comparison.
          </p>
          <figure>
            <img src="figs/evaluate_ind_pre.jpeg" alt="Evaluate Individual Responses">
            <figcaption>Figure 6: Evaluate Individual Responses Functionality</figcaption>
          </figure>
          <p>The tool outputs BLEU-4, ROUGE-L, BERTScore, and Cosine Similarity metrics with visualization support.</p>
          <figure>
            <img src="figs/evaluate_ind_post.jpeg" alt="Evaluate Individual Responses Output">
            <figcaption>Figure 7: Evaluate Individual Responses Output</figcaption>
          </figure>

          <h3 class="title is-4">Evaluating Batch Responses</h3>
          <p>Users can evaluate a batch of responses by uploading two <code>.csv</code> files: 
            <code>reference.csv</code> (ground truth) and <code>candidate.csv</code> (model outputs).
          </p>
          <figure>
            <img src="figs/evaluate_batch_pre.jpeg" alt="Evaluate Batch Responses">
            <figcaption>Figure 8: Evaluate Batch Responses Input</figcaption>
          </figure>
          <p>The system visualizes metric comparisons across the dataset using bar plots.</p>
          <figure>
            <img src="figs/evaluate_batch_post.jpeg" alt="Evaluate Batch Responses Output">
            <figcaption>Figure 9: Evaluate Batch Responses Output</figcaption>
          </figure>

          <h3 class="title is-4">App Parameters</h3>
          <p>The app supports three RAG parameters and eight model-specific generation parameters.</p>

          <h4 class="title is-5">RAG Parameters</h4>
          <ul>
            <li><strong>Embedding_model_name:</strong> Identifier of the embedding model (e.g., <code>openai/text-embedding-ada-002</code>).</li>
            <li><strong>CHUNK_SIZE:</strong> Size of each input chunk in tokens/words/characters.</li>
            <li><strong>K:</strong> Number of top entries to retrieve from the vector store for context injection.</li>
          </ul>

          <h4 class="title is-5">Model Parameters</h4>
          <ul>
            <li><strong>temp:</strong> Controls randomness; higher = more diverse (default: <code>1.0</code>).</li>
            <li><strong>top_p:</strong> Nucleus sampling threshold (default: <code>0.9</code>).</li>
            <li><strong>top_k:</strong> Top-k sampling threshold (default: <code>40</code>).</li>
            <li><strong>tfs_z:</strong> Tail free sampling filter (default: <code>1.0</code>).</li>
            <li><strong>num_ctx:</strong> Max tokens used for context (default: <code>2048</code>).</li>
            <li><strong>repeat_penalty:</strong> Penalizes token repetition (default: <code>1.1</code>).</li>
            <li><strong>mirostat:</strong> Enables adaptive perplexity-based sampling (default: <code>0</code>).</li>
            <li><strong>mirostat_eta:</strong> Learning rate for Mirostat adjustment (default: <code>0.1</code>).</li>
            <li><strong>mirostat_tau:</strong> Target perplexity for Mirostat (default: <code>5.0</code>).</li>
          </ul>

        </div>
      </div>
    </div>
  </div>
</section>




<!-- <section class="section" id="user-guide">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">
          <i class="fas fa-tools"></i> User Guide
        </h2>
        <div class="content has-text-justified">



        </div>
      </div>
    </div>
  </div>
</section> -->



<section class="section" id="Installation">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">
          <i class="fas fa-tools"></i> Installation Manual
        </h2>
        <div class="content has-text-justified">

          <h3 class="title is-4">App Installation</h3>
          <p>To install the app, we have to do the following:</p>
          <ol>
            <li>
              Install Mini-Conda on your computer (if already not installed).
              The following link can be used for installation:
              <a href="https://docs.anaconda.com/miniconda/install/#quick-command-line-install" target="_blank">LINK</a>.
            </li>
            <li>
              Clone the repo using git:
              <pre><code>https://github.com/Nafiz43/EvidenceBot</code></pre>
            </li>
            <li>
              Create and activate a new virtual environment:
              <pre><code>conda create -n EvidenceBot python=3.10.0<br>conda activate EvidenceBot</code></pre>
            </li>
            <li>
              Install all the requirements:
              <pre><code>pip install -r requirements.txt</code></pre>
            </li>
            <li>
              Install Ollama from the following 
              <a href="https://ollama.com/download" target="_blank">LINK</a>.
            </li>
            <li>
              Install Models using Ollama:
              <pre><code>ollama pull MODEL_NAME</code></pre>
              Replace <code>MODEL_NAME</code> with your desired model name. 
              List of all the models is available at this 
              <a href="https://ollama.com/download" target="_blank">link</a>.
            </li>
            <li>
              Open the source directory, where the source code exists. 
              Then, keep the documents that you want to analyze in the <code>DATA_DOCUMENTS</code> folder.
            </li>
            <li>
              Open CLI (Command Line Interface) in the source directory and hit the following command:
              <pre><code>ollama pull MODEL_NAME</code></pre>
            </li>
            <li>
              To run the app, navigate to the project directory and execute the following command:
              <pre><code>sh command.sh</code></pre>
            </li>
          </ol>

          <h4 class="title is-5">Minimum System Requirements</h4>
          <ul>
            <li><strong>Processor:</strong> Modern multi-core CPU (at least 8+ cores)</li>
            <li><strong>RAM:</strong> 32GB minimum</li>
            <li><strong>Storage:</strong> 20GB for application code and dependencies</li>
            <li><strong>GPU:</strong> CUDA-compatible GPU with 8GB+ VRAM</li>
          </ul>
          <p><strong>The amount of VRAM required depends on the model that we want to run. Here is an estimate:</strong></p>
          <ul>
            <li>7B model requires ~4 GB</li>
            <li>13B model requires ~8 GB</li>
            <li>30B model needs ~16 GB</li>
            <li>65B model needs ~32 GB</li>
          </ul>
          <blockquote>
            <strong>Note:</strong> While lower configurations are viable, performance may be compromised, leading to longer execution times and potential system slowdowns.
          </blockquote>

          <h4 class="title is-5">Cloud Deployment Alternative</h4>
          <p>If deploying to cloud infrastructure:</p>
          <ul>
            <li>Standard virtual machine with 8+ vCPUs</li>
            <li>32GB RAM</li>
            <li>GPU acceleration if available</li>
          </ul>

        </div>
      </div>
    </div>
  </div>
</section>




<section class="section" id="Docker">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">
          <i class="fab fa-docker"></i> Docker Installation Manual
        </h2>

        <div class="content has-text-justified">
          <p class="has-text-justified">
          Download the <code>Dockerfile</code> from the given <a href="Dockerfile" target="_blank">link</a>

          Use the following commands to build and run the Docker container securely.
        </p>

        <h3>Build and Run Docker Container</h3>

        <p><strong>1. Build the Docker image:</strong></p>
        <pre><code>docker build -t evidencebot .</code></pre>

        <p><strong>2. Run the Docker container and expose port 8501:</strong></p>
<pre><code>docker run -it --rm -p 8501:8501 -v $(pwd)/DATA_DOCUMENTS:/app/DATA_DOCUMENTS evidencebot</code></pre>

        <p>This command:</p>
        <ul>
          <li>Maps local port <code>8501</code> to container's port <code>8501</code></li>
          <li>Mounts the <code>DATA_DOCUMENTS</code> folder so your documents are accessible inside the container</li>
          <li>Removes the container after it exits (<code>--rm</code>)</li>
        </ul>
        </div>

        
        
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">
          Acknowledgements
        </h2>
        <p>
          This research was supported by the National Science Foundation under Grant No. 2020751, as well as by the Alfred P. Sloan Foundation through the OSPO for UC initiative (Award No. 2024-22424).
        </p> 
      </div>
    </div>
  </div>
</section>

<section class="section" id="License">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">
          License
        </h2>
        <p>
          The EvidenceBot project is licensed under the Apache License 2.0. 
          This permissive license allows you to use, modify, and distribute the software for both personal and commercial purposes, 
          as long as you include proper attribution and comply with the terms outlined in the license.
        </p>
      </div>
    </div>
  </div>






<section class="section" id="Contributing">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">
          Contributing
        </h2>
        <p>
          Contributions are very welcome! If you'd like to add features, fix bugs, or improve the documentation, please feel free to fork the repository and create a pull request. Make sure your changes are well-documented and follow the project's coding standards.
        </p>
        <p>
          We appreciate your interest in improving this project—thank you for helping make it better!
        </p>
      </div>
    </div>
  </div>
</section>


<section class="section" id="Contact">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-left">
        <h2 class="title is-3 has-text-centered">
          Contact
        </h2>
        <p>
          For high-level discussions, funding opportunities, or collaboration inquiries, please reach out to the project supervisor, 
          <strong>Professor Vladimir Filkov</strong> 
          (<a href="mailto:vfilkov@ucdavis.edu">vfilkov@ucdavis.edu</a>).
        </p>
        <p>
          For technical questions, bug reports, or concerns regarding the codebase, please contact the project lead, 
          <strong>Nafiz Imtiaz Khan</strong> 
          (<a href="mailto:nikhan@ucdavis.edu">nikhan@ucdavis.edu</a>).
        </p>

        <p>
          We're excited to hear from you!
        </p>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>@inproceedings{khan2025evidencebot,
  author    = {Nafiz Imtiaz Khan and Vladimir Filkov},
  title     = {EvidenceBot: A Privacy-Preserving, Customizable RAG-Based Tool for Enhancing Large Language Model Interactions},
  booktitle = {Proceedings of the 33rd ACM International Conference on the Foundations of Software Engineering (FSE Companion '25)},
  year      = {2025},
  doi       = {10.1145/3696630.3728607},
  isbn      = {979-8-4007-1276-0/2025/06},
  location  = {Trondheim, Norway},
  publisher = {ACM},
  address   = {New York, NY, USA}
}</code></pre>
  </div>
</section>

<!-- 
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {},
  title     = {},
  journal   = {},
  year      = {},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      
      <a class="icon-link" href="https://github.com/nafiz43" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p class="is-size-7 has-text-grey">
            This front-end website is adapted from the 
            <a href="https://nerfies.github.io/" target="_blank" rel="noopener noreferrer">Nerfies project</a> 
            by Park et al., and is licensed under a 
            <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener noreferrer">
              Creative Commons Attribution-ShareAlike 4.0 International License
            </a>. 
            It has been significantly modified and extended to fit the needs of OSSPREY project.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
